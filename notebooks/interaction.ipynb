{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18109fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import MilvusClient\n",
    "\n",
    "# Initialize Milvus Lite (local file)\n",
    "atlas = MilvusClient(\"geospatial_atlas.db\")\n",
    "\n",
    "# Create Collection\n",
    "if not atlas.has_collection(\"world_anchors\"):\n",
    "    atlas.create_collection(\n",
    "        collection_name=\"world_anchors\",\n",
    "        dimension=64, #alphaearth 64d\n",
    "        metric_type=\"COSINE\",\n",
    "        auto_id=True\n",
    "    )\n",
    "\n",
    "def index_anchors(batch_alpha_vectors, batch_metadata):\n",
    "    data = [\n",
    "        {\"vector\": vec, \"lat\": meta['lat'], \"lon\": meta['lon'], \"s2\": meta['s2']}\n",
    "        for vec, meta in zip(batch_alpha_vectors, batch_metadata)\n",
    "    ]\n",
    "    atlas.insert(collection_name=\"world_anchors\", data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8b6c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def geolocate(image_path, top_k=5):\n",
    "    # 1. Image -> StreetCLIP -> 768D Vector\n",
    "    visual_vec = get_streetclip_embedding(image_path) \n",
    "    \n",
    "    scout.eval()\n",
    "    with torch.no_grad():\n",
    "        query_vector = scout(torch.tensor(visual_vec).to(device)).cpu().numpy()\n",
    "\n",
    "    # 3. 64D Vector -> Milvus Atlas Search\n",
    "    results = atlas.search(\n",
    "        collection_name=\"world_anchors\",\n",
    "        data=[query_vector],\n",
    "        limit=top_k,\n",
    "        output_fields=[\"lat\", \"lon\", \"s2\"]\n",
    "    )\n",
    "    \n",
    "    return results[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73ca64c",
   "metadata": {},
   "source": [
    "figure out how we should interact with it."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
